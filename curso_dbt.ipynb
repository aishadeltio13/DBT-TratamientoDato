{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curso de dbt (Data Build Tool) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción a dbt - Transformando el Mundo de los Datos\n",
    "\n",
    "### Problemas antes de dbt\n",
    "\n",
    "Antes de dbt, los equipos de datos enfrentaban varios desafíos críticos:\n",
    "\n",
    "#### 1. **El Problema del \"Spaghetti Code\"**\n",
    "- Scripts SQL dispersos sin organización clara\n",
    "- Transformaciones complejas en archivos monolíticos\n",
    "- Dependencias implícitas difíciles de rastrear\n",
    "- Falta de modularidad y reutilización\n",
    "\n",
    "#### 2. **Ausencia de Mejores Prácticas de Software**\n",
    "- Testing manual y propenso a errores\n",
    "- Documentación desactualizada o inexistente\n",
    "- Colaboración limitada entre equipos\n",
    "\n",
    "#### 3. **Problemas de Escalabilidad**\n",
    "- Pipelines frágiles que se rompían frecuentemente\n",
    "- Dificultad para onboarding de nuevos desarrolladores\n",
    "- Mantenimiento costoso y tiempo de desarrollo lento\n",
    "\n",
    "### ¿Qué es dbt? \n",
    "\n",
    "**dbt (Data Build Tool) es una herramienta de línea de comandos que permite a los equipos de datos transformar datos en sus warehouses aplicando prácticas de ingeniería de software**.\n",
    "\n",
    "#### Definición Técnica\n",
    "dbt es un **framework de transformación de datos** que:\n",
    "- Compila modelos en SQL puro\n",
    "- Ejecuta transformaciones directamente en el data warehouse\n",
    "- Gestiona dependencias automáticamente\n",
    "- Aplica testing y documentación de forma nativa\n",
    "\n",
    "#### Filosofía Core de dbt\n",
    "```\n",
    "\"dbt does the T in ELT\"\n",
    "(Extract, Load, Transform)\n",
    "```\n",
    "\n",
    "En lugar del ETL tradicional, dbt se centra en el modelo **ELT**:\n",
    "- **Extract & Load**: Ingestar los datos de origen con transformaciones minimas.\n",
    "- **Transform**: dbt se encarga de las transformaciones.\n",
    "\n",
    "### Los Modelos: El Corazón de dbt\n",
    "\n",
    "#### ¿Qué es un Modelo?\n",
    "Un **modelo** en dbt es:\n",
    "- Un archivo `.sql` que contiene una consulta SELECT donde se combina SQL y Jinja\n",
    "- Representa una transformación de datos\n",
    "- Se ejecuta y materializa en el warehouse\n",
    "\n",
    "#### Ejemplo Conceptual\n",
    "```sql\n",
    "select\n",
    "    customer_id,\n",
    "    first_name,\n",
    "    last_name,\n",
    "    email\n",
    "from {{ source('raw_data', 'customers') }}\n",
    "where active = true\n",
    "```\n",
    "\n",
    "### Funciones Especiales que Revolucionan el SQL\n",
    "\n",
    "#### 1. **ref() - Referencias entre Modelos**\n",
    "```sql\n",
    "-- Crea dependencias automáticas\n",
    "select * from {{ ref('staging__customers') }}\n",
    "```\n",
    "\n",
    "#### 2. **source() - Referencias a Datos Raw**\n",
    "```sql\n",
    "-- Referencia a tablas originales\n",
    "select * from {{ source('ecommerce', 'raw_orders') }}\n",
    "```\n",
    "\n",
    "\n",
    "### Componentes Arquitectónicos de dbt\n",
    "\n",
    "#### 1. **El Compilador (Compiler)**\n",
    "- **Función**: Convierte los modelos en SQL puro\n",
    "- **Proceso**:\n",
    "  ```\n",
    "  Módelo dbt → Compilador → SQL ejecutable\n",
    "  ```\n",
    "\n",
    "#### 2. **El Runner (Ejecutor)**\n",
    "- **Función**: Ejecuta el SQL compilado en el data warehouse\n",
    "- **Características**:\n",
    "  - Gestión automática de dependencias gracias al uso de DAGs.\n",
    "  - Ejecución paralela cuando es posible\n",
    "  - Manejo de errores y rollbacks\n",
    "  - Logging detallado de operaciones\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estructura del Proyecto jaffle_shop\n",
    "\n",
    "Nuestro proyecto tiene la siguiente estructura:\n",
    "\n",
    "```\n",
    "jaffle_shop/\n",
    "├── dbt_project.yml          # Configuración del proyecto\n",
    "├── profiles.yml             # Configuración de conexión\n",
    "├── models/\n",
    "│   ├── staging/             # Modelos de preparación (views)\n",
    "│   └── marts/               # Modelos finales (tables)\n",
    "├── macros/                  # Funciones reutilizables\n",
    "├── tests/                   # Tests personalizados\n",
    "└── seeds/                   # Datos raw\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comandos Básicos de dbt\n",
    "\n",
    "### Comandos Esenciales\n",
    "\n",
    "```bash\n",
    "# Verificar configuración\n",
    "dbt debug\n",
    "\n",
    "# Cargar ficheros seed\n",
    "dbt seed\n",
    "\n",
    "# Ejecutar todos los modelos\n",
    "dbt run\n",
    "\n",
    "# Ejecutar un modelo específico\n",
    "dbt run --models staging__order_items\n",
    "\n",
    "# Ejecutar modelos con dependencias\n",
    "dbt run --models marts__customers+\n",
    "\n",
    "# Compilar sin ejecutar\n",
    "dbt compile\n",
    "\n",
    "# Generar fichero yml\n",
    "dbt run-operation generate_model_yaml --args '{\"model_names\": [\"staging__customers\"]}'\n",
    "\n",
    "# Ver la documentación\n",
    "dbt docs generate\n",
    "dbt docs serve\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con `dbt seed` podemos cargar datos de ejemplo en nuestro data warehouse desde archivos CSV ubicados en la carpeta `seeds/`. Estos datos serán datos en raw, los datos de partida, nuestras sources.\n",
    "\n",
    "Ahora imaginemos que estamos interesados en rresponder las siguientes preguntas de negocio:\n",
    "\n",
    "1. ¿Cuántos clientes activos tenemos (con compras en el último mes)?\n",
    "2. ¿Cuál es el total de ventas por producto?\n",
    "3. ¿Cuáles son los 10 productos más vendidos en el último trimestre?\n",
    "\n",
    "Vamos a resolverlos utilizando las tablas que tenemos ahora mismo (las tablas de raw)\n",
    "\n",
    "Podremos resolverlo con querys como las siguientes: \n",
    "\n",
    "```sql\n",
    "-- 1. Clientes activos\n",
    "select \n",
    "  count(distinct customer) as number_of_active_customers \n",
    "from \n",
    "  jaffle_shop.raw.orders\n",
    "where \n",
    "  ORDERED_AT >= '2016-08-01'\n",
    "```\n",
    "```sql\n",
    "-- 2. Total de ventas por producto\n",
    "select \n",
    "    sku, \n",
    "    sum(price) as total_ventas\n",
    "from \n",
    "    jaffle_shop.raw.items\n",
    "group by \n",
    "    sku\n",
    "order by \n",
    "    total_ventas desc\n",
    "```\n",
    "```sql\n",
    "-- 3. Top 10 productos más vendidos desde 2016-07-01\n",
    "select \n",
    "    sku, \n",
    "    sum(units) as unidades_vendidas\n",
    "from\n",
    "    jaffle_shop.raw.items\n",
    "inner join \n",
    "  jaffle_shop.raw.orders\n",
    "on orders.id = items.order_id\n",
    "where \n",
    "    ORDERED_AT >= '2016-07-01' -- Esta comparación puede ser peligrosa\n",
    "group by \n",
    "    sku\n",
    "order by \n",
    "    unidades_vendidas desc\n",
    "limit 10\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capa STAGING\n",
    "\n",
    "Dado que los datos en las tablas raw no están limpios ni estructurados para consultar, el primer paso es crear una capa de staging. Esta capa se encargará de preparar y limpiar los datos para que estén listos para su consulta. La capa staging estará compuesta por modelos dbt que transformen las tablas raw en vistas limpias y estructuradas. Es aqui donde tendremos el primer acercamiento con los modelos de dbt y donde podremos ver la filosofia de dbt en acción.\n",
    "\n",
    "\n",
    "### El Paradigma dbt: Transform First, Questions Later\n",
    "\n",
    "#### Enfoque Tradicional\n",
    "```\n",
    "Pregunta de Negocio → Análisis Ad-hoc → SQL específico → Resultado\n",
    "```\n",
    "\n",
    "#### Enfoque dbt\n",
    "```\n",
    "Datos en bruto → Modelos Base → Modelos Intermedios → Modelos Marts → Múltiples Análisis\n",
    "```\n",
    "\n",
    "**Ventaja**: Una vez construidos los modelos base, responder nuevas preguntas es mucho más rápido.\n",
    "\n",
    "Ahora ya podemos trabajar con las tablas limpias desde el inicio, sin tener que lidiar con los datos sucios de las tablas raw. Pero aún así, para responder ciertas preguntas, tenemos que hacer transformaciones adicionales. Por ejemplo, para calcular el total de ventas por producto y mes, necesitamos unir las tablas de orders e items y realizar agregaciones. Dado que queremos aislar toda la complejidad posible, crearemos una nueva capa intermedia llamada \"intermediate\" donde realizaremos estas transformaciones adicionales antes de llegar a la capa final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capa Intermediate\n",
    "\n",
    "La capa intermediate sirve como puente entre la capa de staging y la capa de marts. En esta capa, realizamos transformaciones adicionales y agregaciones que preparan los datos para su análisis final. Los modelos en esta capa suelen ser más complejos y pueden incluir cálculos específicos del negocio. Añadiremos mayor complejidad, por lo que se distingue de la capa de staging, pero no serán tablas completas para un consumo final, por lo que no estarán en la capa de marts.\n",
    "\n",
    "En este caso crearemos las tablas intermedias:\n",
    "\n",
    "- intermediate__orders_lineitems: Combina las tablas de orders e items, calculando cantidades originales y finales, precios unitarios y subtotales, y si hubo devoluciones.\n",
    "- intermediate__orders: Agrega los datos combinados por fecha, ubicación y cliente, contando el número de productos y sumando cantidades y precios.\n",
    "\n",
    "Ambas presentan una complejidad considerable (una a nivel de producto y otra a nivel de order), pero aún no están listas para el consumo final, por lo que las ubicamos en la capa intermediate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capa Marts\n",
    "\n",
    "La capa marts es la capa final donde los datos están completamente preparados para el análisis y la generación de informes. Los modelos en esta capa suelen ser tablas que contienen métricas clave y dimensiones que los analistas pueden utilizar directamente para responder preguntas de negocio. En esta capa, los modelos son optimizados para el rendimiento y la facilidad de uso. Dado que esta capa está destinada a resolver preguntas, debemos pensar en la estructura de las tablas para que sean intuitivas y fáciles de consultar. \n",
    "\n",
    "Por ejemplo, imaginemos que queremos reponder preguntas como las siguientes:\n",
    "\n",
    "1. ¿Cuántas compras ha hecho cada cliente en el último año?\n",
    "2. ¿Cuál es el total de ventas por producto de los sacados recientemente?\n",
    "3. ¿Cuál es el precio de los 10 productos más vendidos en el último año?\n",
    "4. ¿Qué porcentaje de la compra suponen los productos de comida para cada cliente?\n",
    "\n",
    "Ahora que ya hemos limpiado y enriquecido nuestras tablas, toca crear la última capa: la capa marts. En esta capa, crearemos modelos que respondan directamente a las preguntas de negocio planteadas anteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuración de los Modelos en dbt\n",
    "\n",
    "En dbt, podemos configurar cómo se comportan y materializan nuestros modelos usando el **bloque de configuración (config)**. Esta configuración determina aspectos cruciales como el tipo de materialización, el esquema de destino, las etiquetas, y mucho más.\n",
    "\n",
    "### Formas de Configurar un Modelo\n",
    "\n",
    "#### 1. Configuración en el archivo SQL (Recomendado para configuraciones específicas)\n",
    "```sql\n",
    "{{ config(\n",
    "    materialized='table',\n",
    "    schema='staging',\n",
    "    tags=['daily', 'critical']\n",
    ") }}\n",
    "\n",
    "select\n",
    "    customer_id,\n",
    "    first_name,\n",
    "    last_name\n",
    "from {{ source('raw_data', 'customers') }}\n",
    "```\n",
    "\n",
    "#### 2. Configuración en dbt_project.yml (Para configuraciones globales)\n",
    "```yaml\n",
    "models:\n",
    "  jaffle_shop:\n",
    "    staging:\n",
    "      +materialized: view\n",
    "      +schema: staging\n",
    "    marts:\n",
    "      +materialized: table\n",
    "      +schema: analytics\n",
    "```\n",
    "\n",
    "#### 3. Configuración en archivos .yml de propiedades (menos usado)\n",
    "```yaml\n",
    "models:\n",
    "  - name: staging__customers\n",
    "    config:\n",
    "      materialized: view\n",
    "      tags: ['pii', 'hourly']\n",
    "```\n",
    "\n",
    "### Parámetros de Configuración Más Comunes\n",
    "\n",
    "#### 1. **materialized** - Tipo de Materialización\n",
    "Define cómo se crea el modelo en el warehouse:\n",
    "\n",
    "```sql\n",
    "-- Vista (recalcula en cada consulta)\n",
    "{{ config(materialized='view') }}\n",
    "\n",
    "-- Tabla física (se reconstruye completamente)\n",
    "{{ config(materialized='table') }}\n",
    "\n",
    "-- Incremental (solo añade/actualiza nuevos registros)\n",
    "{{ config(materialized='incremental') }}\n",
    "\n",
    "-- Ephemeral (solo existe en compilación, no se crea en warehouse)\n",
    "-- Equivalente a un alias\n",
    "{{ config(materialized='ephemeral') }}\n",
    "```\n",
    "\n",
    "#### 2. **schema** - Esquema de Destino\n",
    "```sql\n",
    "{{ config(schema='staging') }}\n",
    "\n",
    "-- Se creará en: <target_schema>_staging\n",
    "-- Ejemplo: jaffle_shop_staging\n",
    "```\n",
    "\n",
    "#### 3. **alias** - Nombre Personalizado de la Tabla\n",
    "```sql\n",
    "{{ config(alias='customer_data') }}\n",
    "\n",
    "-- En lugar de \"staging__customers\"\n",
    "-- Se creará como \"customer_data\"\n",
    "```\n",
    "\n",
    "#### 4. **tags** - Etiquetas para Organización\n",
    "```sql\n",
    "{{ config(tags=['daily', 'core', 'pii']) }}\n",
    "\n",
    "-- Permite ejecutar grupos de modelos:\n",
    "-- dbt run --models tag:daily\n",
    "-- dbt run --models tag:pii\n",
    "```\n",
    "\n",
    "#### 5. **enabled** - Habilitar/Deshabilitar Modelo\n",
    "```sql\n",
    "{{ config(enabled=false) }}\n",
    "\n",
    "-- El modelo no se ejecutará ni compilará\n",
    "-- Útil para deprecar modelos temporalmente\n",
    "```\n",
    "\n",
    "#### 6. **unique_key** - Clave para Modelos Incrementales\n",
    "```sql\n",
    "{{\n",
    "    config(\n",
    "        materialized='incremental',\n",
    "        unique_key='order_id'\n",
    "    )\n",
    "}}\n",
    "\n",
    "select * from {{ ref('staging__orders') }}\n",
    "\n",
    "{% if is_incremental() %}\n",
    "where order_date > (select max(order_date) from {{ this }})\n",
    "{% endif %}\n",
    "```\n",
    "\n",
    "#### 7. **pre_hook** y **post_hook** - Hooks SQL\n",
    "```sql\n",
    "{{\n",
    "    config(\n",
    "        pre_hook=\"grant usage on schema {{ schema }} to role analyst\",\n",
    "        post_hook=\"grant select on {{ this }} to role analyst\"\n",
    "    )\n",
    "}}\n",
    "\n",
    "-- Se ejecutan antes/después de materializar el modelo\n",
    "```\n",
    "\n",
    "### Precedencia de Configuración\n",
    "\n",
    "La configuración se aplica en el siguiente orden (de menor a mayor prioridad):\n",
    "\n",
    "1. **dbt_project.yml** (configuración global)\n",
    "2. **Archivos .yml de propiedades** (configuración por modelo)\n",
    "3. **Bloque config en archivo .sql** (configuración específica)\n",
    "4. **Línea de comandos** (dbt run --vars)\n",
    "\n",
    "```sql\n",
    "-- Esto sobrescribe configuraciones previas\n",
    "{{ config(materialized='table') }}\n",
    "\n",
    "-- Incluso si dbt_project.yml dice:\n",
    "-- +materialized: view\n",
    "```\n",
    "\n",
    "### Mejores Prácticas\n",
    "\n",
    "1. **Usa config en SQL para configuraciones específicas del modelo**\n",
    "   - Materializaciones especiales\n",
    "   - unique_key para incrementales\n",
    "\n",
    "2. **Usa dbt_project.yml para configuraciones por carpeta**\n",
    "   - Todos los staging como views\n",
    "   - Todos los marts como tables\n",
    "\n",
    "3. **Documenta decisiones de configuración**\n",
    "   ```sql\n",
    "   {{ config(\n",
    "       materialized='incremental',\n",
    "       -- Incremental porque esta tabla tiene >100M filas\n",
    "       -- y se actualiza cada hora\n",
    "       unique_key='log_id'\n",
    "   ) }}\n",
    "   ```\n",
    "\n",
    "4. **Usa tags para organización y ejecución selectiva**\n",
    "   ```bash\n",
    "   dbt run --models tag:daily     # Solo modelos diarios\n",
    "   dbt run --models tag:pii       # Solo datos sensibles\n",
    "   dbt run --models tag:critical  # Solo tablas críticas\n",
    "   ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentación en dbt\n",
    "\n",
    "### ¿Por qué es Importante la Documentación?\n",
    "\n",
    "Antes de dbt, la documentación de datos era:\n",
    "- ❌ Manual y propensa a quedar desactualizada\n",
    "- ❌ Dispersa en wikis, Google Docs o Confluence\n",
    "- ❌ Difícil de mantener sincronizada con el código\n",
    "- ❌ Poco accesible para analistas de negocio\n",
    "\n",
    "**dbt revoluciona la documentación al:**\n",
    "- ✅ Generarla automáticamente desde el código\n",
    "- ✅ Mantenerla junto al código (fuente única de la verdad)\n",
    "- ✅ Crear un sitio web interactivo con linaje de datos\n",
    "- ✅ Facilitar la colaboración entre equipos técnicos y de negocio\n",
    "\n",
    "---\n",
    "\n",
    "### Generación Automática de Archivos YAML\n",
    "\n",
    "Antes de documentar manualmente, dbt ofrece herramientas para **generar automáticamente la estructura base de los archivos YAML**. Esto ahorra tiempo y asegura que no olvidemos ninguna columna.\n",
    "\n",
    "#### El Paquete `codegen`\n",
    "\n",
    "**codegen** es un paquete de dbt que proporciona macros para generar código automáticamente, incluyendo archivos YAML de documentación.\n",
    "\n",
    "##### Instalación\n",
    "\n",
    "1. **Agregar el paquete en `packages.yml`:**\n",
    "```yaml\n",
    "# packages.yml (en la raíz del proyecto)\n",
    "packages:\n",
    "  - package: dbt-labs/codegen\n",
    "    version: 0.12.1\n",
    "```\n",
    "\n",
    "2. **Instalar las dependencias:**\n",
    "```bash\n",
    "dbt deps\n",
    "```\n",
    "\n",
    "Esto descargará el paquete codegen en la carpeta `dbt_packages/`.\n",
    "\n",
    "#### Comando: `generate_model_yaml`\n",
    "\n",
    "Este comando genera automáticamente la estructura YAML para uno o varios modelos, incluyendo:\n",
    "- Nombre del modelo\n",
    "- Lista completa de columnas\n",
    "- Tipos de datos\n",
    "\n",
    "##### Sintaxis Básica\n",
    "\n",
    "```bash\n",
    "dbt run-operation generate_model_yaml --args '{\"model_names\": [\"nombre_modelo\"]}'\n",
    "```\n",
    "\n",
    "##### Ejemplos Prácticos\n",
    "\n",
    "**Ejemplo 1: Generar YAML para un solo modelo**\n",
    "\n",
    "```bash\n",
    "cd jaffle_shop\n",
    "dbt run-operation generate_model_yaml --args '{\"model_names\": [\"staging__customers\"]}'\n",
    "```\n",
    "\n",
    "**Ejemplo 2: Generar YAML para múltiples modelos**\n",
    "\n",
    "```bash\n",
    "dbt run-operation generate_model_yaml --args '{\"model_names\": [\"staging__customers\", \"staging__orders\", \"staging__products\"]}'\n",
    "```\n",
    "\n",
    "#### Flujo de Trabajo Recomendado\n",
    "\n",
    "1. **Crear el modelo SQL**\n",
    "   ```sql\n",
    "   -- models/staging/staging__customers.sql\n",
    "   select\n",
    "       id as customer_id,\n",
    "       first_name,\n",
    "       last_name,\n",
    "       email\n",
    "   from {{ source('raw', 'customers') }}\n",
    "   ```\n",
    "\n",
    "2. **Ejecutar el modelo para crear la tabla**\n",
    "   ```bash\n",
    "   dbt run --models staging__customers\n",
    "   ```\n",
    "\n",
    "3. **Generar el YAML automáticamente**\n",
    "   ```bash\n",
    "   dbt run-operation generate_model_yaml --args '{\"model_names\": [\"staging__customers\"]}'\n",
    "   ```\n",
    "\n",
    "4. **Copiar la salida a un archivo YAML**\n",
    "   ```bash\n",
    "   # Crear o editar el archivo\n",
    "   # models/staging/staging__customers.yml\n",
    "   ```\n",
    "   \n",
    "   Pegar la salida generada y guardar.\n",
    "\n",
    "5. **Completar las descripciones manualmente**\n",
    "   ```yaml\n",
    "   version: 2\n",
    "\n",
    "   models:\n",
    "     - name: staging__customers\n",
    "       description: \"Datos limpios de clientes desde la tabla raw\"\n",
    "       columns:\n",
    "         - name: customer_id\n",
    "           description: \"Identificador único del cliente (PK)\"\n",
    "           tests:\n",
    "             - unique\n",
    "             - not_null\n",
    "         \n",
    "         - name: first_name\n",
    "           description: \"Nombre del cliente\"\n",
    "         \n",
    "         - name: last_name\n",
    "           description: \"Apellido del cliente\"\n",
    "         \n",
    "         - name: email\n",
    "           description: \"Email de contacto del cliente\"\n",
    "           tests:\n",
    "             - unique\n",
    "   ```\n",
    "\n",
    "#### Ventajas de la Generación Automática\n",
    "\n",
    "✅ **Ahorro de tiempo**: No escribir manualmente cada columna\n",
    "\n",
    "✅ **Cero errores de tipeo**: Los nombres se extraen directamente del warehouse\n",
    "\n",
    "✅ **Completitud**: No olvidarás documentar ninguna columna\n",
    "\n",
    "✅ **Punto de partida**: Estructura base lista para agregar descripciones\n",
    "\n",
    "✅ **Escalabilidad**: Puedes generar YAML para decenas de modelos rápidamente\n",
    "\n",
    "#### Limitaciones\n",
    "\n",
    "⚠️ **No genera descripciones**: Las descripciones quedan vacías, debes completarlas manualmente\n",
    "\n",
    "⚠️ **No añade tests**: Debes agregar los tests según tus necesidades\n",
    "\n",
    "⚠️ **Sobrescribe**: Ten cuidado de no sobrescribir YAML existente con documentación\n",
    "\n",
    "---\n",
    "\n",
    "### El Comando dbt docs\n",
    "\n",
    "Una vez que tienes tus archivos YAML (generados automáticamente o escritos manualmente), dbt puede crear un sitio web de documentación interactivo.\n",
    "\n",
    "dbt incluye dos comandos principales para documentación:\n",
    "\n",
    "#### 1. `dbt docs generate`\n",
    "```bash\n",
    "dbt docs generate\n",
    "```\n",
    "\n",
    "**¿Qué hace?**\n",
    "- Extrae información de los modelos, tests, fuentes y macros\n",
    "- Lee las descripciones de los archivos `.yml`\n",
    "- Genera metadatos sobre columnas, tipos de datos y dependencias\n",
    "- Crea archivos JSON con toda la información (`manifest.json` y `catalog.json`)\n",
    "\n",
    "**Archivos generados:**\n",
    "```\n",
    "target/\n",
    "├── manifest.json      # Estructura del proyecto, dependencias, configuraciones\n",
    "└── catalog.json       # Metadatos del warehouse (tipos de columnas, estadísticas)\n",
    "```\n",
    "\n",
    "#### 2. `dbt docs serve`\n",
    "```bash\n",
    "dbt docs serve\n",
    "```\n",
    "\n",
    "**¿Qué hace?**\n",
    "- Inicia un servidor web local (generalmente en `http://localhost:8080`)\n",
    "- Presenta un sitio interactivo con toda la documentación\n",
    "- Permite navegar por modelos, dependencias y linaje de datos\n",
    "- Incluye búsqueda y filtrado avanzado\n",
    "\n",
    "**Para detenerlo:** Presiona `Ctrl+C` en la terminal\n",
    "\n",
    "---\n",
    "\n",
    "### Cómo Documentar tus Modelos Manualmente\n",
    "\n",
    "Después de generar la estructura base con codegen, es importante completar y enriquecer la documentación.\n",
    "\n",
    "#### 1. Documentación Básica en Archivos YAML\n",
    "\n",
    "```yaml\n",
    "# models/staging/schema.yml\n",
    "version: 2\n",
    "\n",
    "models:\n",
    "  - name: staging__customers\n",
    "    description: |\n",
    "      Datos de clientes limpios y estandarizados desde la tabla raw.\n",
    "      Cada registro representa un cliente único.\n",
    "      \n",
    "      **Transformaciones aplicadas:**\n",
    "      - Renombrado de columnas a snake_case\n",
    "      - Conversión de tipos de datos\n",
    "      - Eliminación de registros duplicados\n",
    "    \n",
    "    columns:\n",
    "      - name: customer_id\n",
    "        description: \"Identificador único del cliente (PK)\"\n",
    "        tests:\n",
    "          - unique\n",
    "          - not_null\n",
    "      \n",
    "      - name: first_name\n",
    "        description: \"Nombre del cliente\"\n",
    "      \n",
    "      - name: last_name\n",
    "        description: \"Apellido del cliente\"\n",
    "      \n",
    "      - name: email\n",
    "        description: \"Email de contacto del cliente\"\n",
    "        tests:\n",
    "          - unique\n",
    "          - not_null\n",
    "```\n",
    "\n",
    "#### 2. Documentación de Fuentes (Sources)\n",
    "\n",
    "```yaml\n",
    "# models/staging/sources.yml\n",
    "version: 2\n",
    "\n",
    "sources:\n",
    "  - name: raw\n",
    "    description: \"Datos crudos importados del sistema transaccional\"\n",
    "    database: jaffle_shop\n",
    "    schema: raw\n",
    "    \n",
    "    tables:\n",
    "      - name: customers\n",
    "        description: |\n",
    "          Tabla de clientes del sistema de e-commerce.\n",
    "          Actualizada cada noche a las 2:00 AM UTC.\n",
    "        \n",
    "        columns:\n",
    "          - name: id\n",
    "            description: \"ID único del cliente\"\n",
    "            tests:\n",
    "              - unique\n",
    "              - not_null\n",
    "          \n",
    "          - name: first_name\n",
    "            description: \"Nombre del cliente\"\n",
    "```\n",
    "\n",
    "#### 3. Documentación Avanzada con Metadatos\n",
    "\n",
    "```yaml\n",
    "models:\n",
    "  - name: marts__customers\n",
    "    description: \"Tabla analítica de métricas agregadas por cliente\"\n",
    "    \n",
    "    meta:\n",
    "      owner: \"Data Analytics Team\"\n",
    "      update_frequency: \"Daily at 3:00 AM\"\n",
    "      maturity: \"production\"\n",
    "      contains_pii: true\n",
    "    \n",
    "    columns:\n",
    "      - name: customer_id\n",
    "        description: \"Identificador único del cliente\"\n",
    "        meta:\n",
    "          sensitive: false\n",
    "      \n",
    "      - name: lifetime_spend\n",
    "        description: |\n",
    "          Gasto total del cliente desde su primer pedido.\n",
    "          **Fórmula:** Suma de subtotal + tax + shipping de todos los pedidos\n",
    "        meta:\n",
    "          unit: \"USD\"\n",
    "          calculation: \"sum(order_total)\"\n",
    "```\n",
    "\n",
    "### Características del Sitio de Documentación\n",
    "\n",
    "#### 1. **Vista General del Proyecto**\n",
    "- Lista de todos los modelos organizados por carpeta\n",
    "- Estadísticas del proyecto (número de modelos, tests, fuentes)\n",
    "- Búsqueda global por nombre o descripción\n",
    "\n",
    "#### 2. **Vista de Modelo Individual**\n",
    "Cada modelo muestra:\n",
    "- Descripción detallada\n",
    "- Lista de columnas con tipos y descripciones\n",
    "- Tests configurados\n",
    "- Código SQL compilado\n",
    "- Linaje de datos (dependencies upstream y downstream)\n",
    "\n",
    "#### 3. **Gráfico de Linaje (DAG)**\n",
    "- Visualización interactiva de dependencias\n",
    "- Navegación por el grafo de transformaciones\n",
    "- Identificación de modelos upstream (fuentes) y downstream (consumidores)\n",
    "\n",
    "**Ejemplo de navegación:**\n",
    "```\n",
    "raw_customers → staging__customers → intermediate__customer_orders → marts__customers\n",
    "```\n",
    "\n",
    "#### 4. **Documentación de Macros**\n",
    "- Descripción de macros personalizados\n",
    "- Parámetros de entrada y salida\n",
    "- Ejemplos de uso\n",
    "\n",
    "#### 5. **Información del Warehouse**\n",
    "- Tipos de datos de cada columna (extraídos del warehouse)\n",
    "- Número de filas (si está disponible)\n",
    "- Última actualización\n",
    "\n",
    "### Flujo de Trabajo Completo Recomendado\n",
    "\n",
    "```bash\n",
    "# 1. Desarrollar modelo SQL\n",
    "# models/marts/marts__customers.sql\n",
    "\n",
    "# 2. Ejecutar modelo\n",
    "dbt run --models marts__customers\n",
    "\n",
    "# 3. Generar YAML base automáticamente\n",
    "dbt run-operation generate_model_yaml --args '{\"model_names\": [\"marts__customers\"]}'\n",
    "\n",
    "# 4. Copiar salida a schema.yml y añadir descripciones y tests\n",
    "# models/marts/schema.yml\n",
    "\n",
    "# 5. Generar documentación\n",
    "dbt docs generate\n",
    "\n",
    "# 6. Visualizar documentación\n",
    "dbt docs serve\n",
    "\n",
    "# 7. Revisar en navegador (http://localhost:8080)\n",
    "# - Ver descripción del modelo\n",
    "# - Revisar linaje de datos\n",
    "# - Validar que columnas están documentadas\n",
    "```\n",
    "\n",
    "### Mejores Prácticas de Documentación\n",
    "\n",
    "#### 1. **Documenta el \"Por Qué\", No el \"Qué\"**\n",
    "```yaml\n",
    "# ❌ Malo - describe lo obvio\n",
    "- name: customer_count\n",
    "  description: \"Número de clientes\"\n",
    "\n",
    "# ✅ Bueno - explica el propósito y lógica\n",
    "- name: customer_count\n",
    "  description: |\n",
    "    Número de clientes únicos activos en los últimos 90 días.\n",
    "    Un cliente se considera activo si ha realizado al menos un pedido.\n",
    "```\n",
    "\n",
    "#### 2. **Documenta Decisiones de Negocio**\n",
    "```yaml\n",
    "models:\n",
    "  - name: marts__revenue\n",
    "    description: |\n",
    "      Métricas de ingresos para reportes ejecutivos.\n",
    "      \n",
    "      **Nota importante:** Los ingresos excluyen pedidos cancelados\n",
    "      y devoluciones, siguiendo la definición de CFO del Q2 2024.\n",
    "      \n",
    "      Para ingresos brutos (incluyendo devoluciones), usar\n",
    "      marts__revenue_gross en su lugar.\n",
    "```\n",
    "\n",
    "#### 3. **Usa Markdown para Formato**\n",
    "```yaml\n",
    "columns:\n",
    "  - name: customer_tier\n",
    "    description: |\n",
    "      Segmentación del cliente basada en lifetime value:\n",
    "      \n",
    "      - **VIP**: LTV > $10,000\n",
    "      - **Premium**: LTV entre $5,000 - $10,000\n",
    "      - **Standard**: LTV entre $1,000 - $5,000\n",
    "      - **New**: LTV < $1,000\n",
    "```\n",
    "\n",
    "#### 4. **Documenta Transformaciones Complejas**\n",
    "```yaml\n",
    "- name: churn_probability\n",
    "  description: |\n",
    "    Probabilidad de abandono del cliente en los próximos 30 días.\n",
    "    \n",
    "    **Modelo:** Regresión logística entrenada en datos históricos\n",
    "    **Variables:** días desde último pedido, frecuencia de compra, ticket promedio\n",
    "    **Última actualización del modelo:** 2024-01-15\n",
    "```\n",
    "\n",
    "#### 5. **Mantén Documentación Cercana al Código**\n",
    "```\n",
    "models/\n",
    "├── marts/\n",
    "│   ├── marts__customers.sql\n",
    "│   └── marts__customers.yml          # Documentación en el mismo directorio\n",
    "```\n",
    "\n",
    "### Beneficios de una Buena Documentación\n",
    "\n",
    "1. **Onboarding más rápido**: Nuevos analistas entienden el modelo de datos rápidamente\n",
    "2. **Colaboración mejorada**: Equipos técnicos y de negocio hablan el mismo idioma\n",
    "3. **Debugging más fácil**: El linaje de datos ayuda a rastrear problemas\n",
    "4. **Confianza en los datos**: Transparencia sobre qué representan las métricas\n",
    "5. **Self-service analytics**: Analistas pueden explorar datos sin ayuda constante\n",
    "\n",
    "\n",
    "Ahora que sabes cómo generar y documentar tus modelos, veamos cómo validar que funcionan correctamente con **testing**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing en dbt\n",
    "\n",
    "### Tipos de Tests\n",
    "\n",
    "#### 1. Tests Genéricos\n",
    "- `unique`: Valores únicos\n",
    "- `not_null`: Sin valores nulos\n",
    "- `accepted_values`: Valores permitidos\n",
    "- `relationships`: Integridad referencial\n",
    "\n",
    "#### 2. Tests Personalizados\n",
    "```sql\n",
    "-- tests/assert_no_negative_customer_metrics.sql\n",
    "select customer_id\n",
    "from {{ ref('marts__customers') }}\n",
    "where lifetime_spend < 0\n",
    "   or count_lifetime_orders < 0\n",
    "```\n",
    "\n",
    "### Ejemplo de Configuración de Tests\n",
    "```yaml\n",
    "# tests/properties.yml\n",
    "models:\n",
    "  - name: marts__customers\n",
    "    columns:\n",
    "      - name: customer_id\n",
    "        tests:\n",
    "          - unique\n",
    "          - not_null\n",
    "      - name: customer_type\n",
    "        tests:\n",
    "          - accepted_values:\n",
    "              values: ['new', 'returning']\n",
    "```\n",
    "\n",
    "### Ejecutar Tests\n",
    "```bash\n",
    "# Todos los tests\n",
    "dbt test\n",
    "\n",
    "# Tests de un modelo específico\n",
    "dbt test --models marts__customers\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
